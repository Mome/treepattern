	%% LyX 2.1.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english]{article}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage[]{algorithm2e}
\usepackage{newlfont}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{tgcursor}
\usepackage{glossaries}
\usepackage{rotating}
\usepackage{adjustbox}
\usepackage{mdframed}
\usepackage{pdflscape}

\graphicspath{ {images/} }
\lstset{basicstyle=\ttfamily}

\begin{document}

\title{A domain-specific language to transform parse-trees into graph-structures.}


\author{Moritz Meier}

\maketitle

\section{Introduction}

Due to the imense complexity and ambiguity of human language, information extraction (IE) from written natural language remains an unsolved problem. 

The DSL (Domain-Specific Language) and the underlying algorithm, described in the work, was designed to transform a phrase structure parse-tree into a graph of semantic relations. However it can in principle be used on any tree structure to produce other kinds of graph structures. The method also includes that additional propertries can be assigend to nodes of trees such that inforamtion of other sources, common in computational linguistics, can incorporated into on representation. The DSL makes it convinient to define pairs of patterns, that act locally on the tree, and corrisponding transistions to form and transform nodes and edges of a graph.
In case the reader is unfamiliar with the abbreviation used for constituents, here is a list of all tags used in the Stanford Parser: \url{http://github.com/mome/treepattern/wiki/List-of-Constituent-Tags}.

\subsection{Motivation}

If we consider natural language as a \textit{serialation of mental content}, which is decoded and encoded by humans in order to communicate. If we also define a formal language that can partially express mental content, than there must be a method which can partially map natural language to the formal language. Furtheron we can see that natural lanuage has a (mostly) modular architecture. Words can be composed syntactically to form a unit with a composed meaning. Linguistics calls this composable units \textit{constiutens} but in different theories different parts of a sententence qualify as a constituent.
Phrase-structure grammars are a common way assign a hierachical structure of constituents to a sentence. They are context-free grammars that yield a parse tree with words as terminal symboles and nodes refering to constituentns of the sentence. Despite beeing a syntactic method, phrase-structure parse trees also carry semantic information. Constituents can refer to entities or concepts, others express relations between concepts.
Computational linguistics possesses various other isolated methods to provide information about the parts of a sentence. POS-tagging finds the syntactic role of words, lemmatization removes inflection, NER-tagging assigs nouns to (semantic) categories.

\subsection{Related Work}

The possibly best known example for pattern matching in words and constituents of a sentence for relation extractions are Hearst-Patterns.
example Pattern Matching in trees is used in various different contexts.
Another python package \textit{ptTools }ialso defines a DNS for pattern matching in parse trees, it is however intended to be applied on python parse trees for code analysis and testing. In other cases pattern matching is used to construct dependency parse trees from phrase structure parse tress {[}citation{]}.
In \cite{rim_transforming_1990} dependency-parse trees are transfored into semantic-graphs.

\subsection{XPath}
The XML Path Language (or short XPath) is a query language for node selection in XML documents. The version XPath 3.0 is currently a WC3 Recommendation and in wide use. The following description are respective to XPath 1.0.
Figure \ref{fig:xpath} shows elven of the thirteen different relationships that can be expressed in XPath. All relationships are defined in relative to a node denoted as \textit{self}. On the vertical axis there is \textit{parent}, \textit{ancestor} and \textit{ancestor-or-self} in the upward direction and \textit{child}, \textit{descendent} and \textit{descendent-or-self} in the downward direction. On the horizontal axes there is \textit{preceding} and \textit{preceding-sibling} on the left and \textit{following} and \textit{following-sibling} to the right.



\begin{figure}

\centering
\includegraphics[scale=0.6]{pathx_axes}
\caption{Subset of relationships expressable in XPath}
\label{fig:xpath}

\end{figure}

\subsection{The Imidiate-Follower Relationship}

Another aim of this work is to define patterns in the same way as Hearst-Patterns are defined. The first pattern from the original publication looks like this:

\[
NP_0\ such\ as\ \{NP_1,\ NP_2\ ...\ ,(and|or)\}\ NP_n
\]

In this representation words and constituency tags are just put in a row seperated by whitespace. While this looks very intuitiv to a human, the technical formulation of the underlying relation, which is crucial for an actual implemntation, requieres some explanation.

Figure 1 visualizes the basic relationships that can be expressed
in XPath in order to construct more complex patterns. Patterns can
be matched on two axes, relative to a matching node denoted as \textit{self}.
On the vertical axis a higher level node can be mached as \textit{ancestor},
a lower as \textit{decendant}. A ancestor of first degree is a \textit{parent}
and a decendent of first degree a \textit{child}. On the horizontal
axis \textit{preceding} and \textit{following} nodes can be matched.
If a preceding or following also happens to be a sibling, it can be
matched with \textit{preceding-sibling} and \textit{following-sibling}.
\begin{figure}
\centering
\includegraphics[scale=0.5]{lara_drinks_tea}
\caption{Phrase-structure parse tree: yellow nodes have no preceding nodes, blue nodes are imidiate followers of 'Lara'.}
\end{figure}

Lets reduce the Hearst-Pattern syntax to just words and constituents tags in a row. How to decide what pattern matches a tree and what not? Figure 2 shows a phrase-structure parse tree of the sentence: "Lara drinks tea.". A Hearst-Pattern like \lstinline{NP drinks NN .} would match, wheres \lstinline{NP VP tea .} would not, because \lstinline{VP} is an ancestor of \lstinline{tea}.
The nodes that can be in the beginning of a pattern are exacltly the once that have no predecessor (yellow in Figure 2). If we choose 'Lara' as our first node. The next possible in a matching pattern are: \lstinline{VP}, \lstinline{VBZ} or \lstinline{drinks} (marked with blue). In general the constituents that can stand at the next position in a pattern hold a relation called \textit{imidiate-following} to the previous constituent. If a node has preceding siblings, than the first preceding sibling is a imidiate follower. If a node has no preceding siblings than the first preceding sibling of the closest ancestor with preceding siblings is an imidiate follower. The first child of a imidiate follower is a imidiate follower.


\section{Funktionsweise}
In the first step the algorithm creates a representation of the sententence structure, called the \textit{property tree}, that incorporates diffenrent sources of information. I is based on the phrase-structure parse tree with additional propertries assigned to the nodes of the tree, which I will just refere to as constituents from here on. For example if the named-entity of a word is 'person', a new variable with the name 'ner' and that value is created and assigned to the corresponding constituent.
In the second step a set of rules defines the way how certain configurations of constituents is translated into semantic domain. A rule consists of four parts, each separated by a collon: 

\[
\mathtt{root\text{-}pattern\ :\ pattern\ :\ relations\ :\ transformations}
\] 

The \textit{root-pattern} specifies constrains for a constituent, that forms the root node of a subtree within the property tree. The \textit{pattern} is a list of constituent constriaints. A pattern is mached in the subtree defined by the root-pattern. The relations part defines edges of graph. The transformations assigns one of the constituents matched in the pattern part to the root-constituents (like the head in dependency grammars). A following rule that tries to build a realation with the root-constituent will subsequently point the head-constituent. 
 







\section{Language Features}
A program in the Domain-Specific Language consists of a list of rules. Each rule consists of four parts (root-pattern, pattern, relations and transformations), each separated by a collon: 

\[
\mathtt{root\text{-}pattern\ :\ pattern\ :\ relations\ :\ transformations}
\]

It can be red in the following way: First find a node that matches the root-pattern

Root-pattern and pattern are instructions to the pattern-matcher, the last two are define 
The head part defines the highest node, of a subtree in wich the pattern
can be matched. The pattern part is a list of terminals or constituents,
which implicitely defines a series of next-potential-follower relations.
The tansformation defines a function call.

The pattern part consists of a series of graph relations. The graph
relations are for once the graph relations also available in XPath
(child, parent, sibling, follower, ancestor) and for the other a series
of imidiate-follower relations, written in the Hearst-Pattern style.

The predicate part defines the semantic relations between the matched
strings. 

\paragraph{Macros}{
	Macros are syntactic sugar for matching multiple options.  The list bilow contains all macros currently in the system:

	\begin{lstlisting}
  V  = {VB, VBD, VBG, VBN, VBP, VBZ}
  N  = {NN, NNS, NNP, NNPS, PRP}
  W  = {WHADJP, WHAVP, WHNP, WHPP}
  SS = {S, SBAR, SBARQ, SINV, SQ}
  J  = {JJ, JJR, JJS}
	\end{lstlisting}

	With \lstinline{V} standing for verbs, \lstinline{N} for nouns, \lstinline{W} for questions, \lstinline{SS} for sentences and \lstinline{J} for adjectives. They can be used just as other variables. 
}

\paragraph{Property matching}
Matching of other properties than 'terminal' or 'label' is expressed in squared brackets after the variable name. Write a variable name and a value separated by an equal sign to check if a node has a property with that name and value. The expression \lstinline{N[ner=person]} matches nouns with the NER-tag 'person'. Write only the variable name to check if a node has a propertry with that name. \lstinline{J[color]} matches adjectives with the property 'color'. Multiple constraints are separeted by a comma: \lstinline{N[ner=person | gender=female]}.
The right hand side of a property constraint can also be a set values. In this case a constitiuent must have one of these properties to match. Example: \lstinline|DT[terminal={an,a}]| - matches a determiner with terminal 'a' or 'an'.

\paragraph{Multiple and Optional parsing}
Variables defined in pattern can occure multiple times to match multiple constituents. The relations defind for that variable are consequently applied to all matches. Example: The rule \lstinline{S : N V and V . : N-V : S} 
contains two time the variable \lstinline{V}. The rule applied to "Hanna walks and talks." will match 'walks' as well as 'talks' for \lstinline{V}. So the relation \lstinline{N-V} is formed two times, resulting in: (Hanna)$\rightarrow$ [walks], and (Hanna)$\rightarrow$ [talks].
Three postfix operators, inspiered by regular expressions, can be added to the end of a pattern token, to make the match optional or repetitive. Multiple nodes assigned to a variable are handled in same way as before.

\begin{tabular}{cll}
	$\mathbf{?}$ & optional & match once or do not match\\
	$+$ & mutliple & match at least once\\
	$*$ & multinal & match arbitrary times (inlcuding: do not match)
\end{tabular}

Example: \lstinline{NP : DT? J* N : J-N : N} matches a noun with or with or without a preceding determiner and arbitrary adjectives.


\paragraph{Cluster references}
If a sentence contains a dependent clause, one part of the sentence referece to another part of the sentence. For this purpose it is possible to specifiy a subgraph instead of a node as the head. If the root of a rule is equal to its transistions, the entities refering to the ancestors of a matching constituent will be put into a cluster. If another entity wants to point to the entity representing the root match, it will point to the cluster instead.


\begin{figure}
\centering
\includegraphics[width=.5\linewidth]{cluster_reference_parsetree}

\lstset{
	%caption=Descriptive Caption Text,
	numbers=left,
	frame=tb,
	xleftmargin=.15\textwidth, xrightmargin=.15\textwidth
} 

\begin{lstlisting}
SS : NP VP .? : NP-VP : SS
SS : IN SS1   :       : SS1
VP : V  SS    : V-SS  : V
\end{lstlisting}

\includegraphics[width=.7\linewidth]{cluster_reference_graph}

\caption{Cluster references Root and tail of line 1 are both SS: ... Line 2: "that" is ommited. Line 3: make an edge beteween the verb of the first part ("said") and the dependent clause "Lara smokes". }
\end{figure}



\paragraph{Head Splitting}
For some sentences it is desireable to let a node point to multiple other nodes. Consider this conjunction of two verb phrases: "Bob runs and cries."

\begin{figure}
\centering

%\textbf{Head Splitting }\par\medskip

\includegraphics[width=.5\linewidth]{headsplit_parsetree}



\begin{lstlisting}[frame=tb, xleftmargin=.2\textwidth, xrightmargin=.2\textwidth]
 SS : NP VP . : NP-VP : SS
 VP : VP1 CC VP2 :: VP1 VP2 
\end{lstlisting}

\includegraphics[width=.3\linewidth]{headsplit_graph}

\caption{\label{Head Splitting} The rules in the middle applied to the parsetree on the top yield the graph in the bottom.}

\end{figure}



\paragraph{Predicate Mode}
In predicate mode the relations part of a rule will define predicates instead of edges, with a slide changed of syntax. Example: 

\begin{lstlisting}
S : NP1 is mother of NP2 : mother_of(NP1,NP2) : S
\end{lstlisting}


\section{Algorithm}

1 parse sentence
2 create property tree from parsetree
3 for each rule
	3.1 find subtrees where root node matches head constraints
	3.2 for each subtree
		3.2.1 find nodes without preceding nodes
		3.2.2 for each node match pattern

\begin{algorithm}
\SetAlgoLined
\SetKwProg{Fn}{Function}{:}{end}
\SetKwFunction{MatchPattern}{MatchPattern}
\SetKwFunction{FindMatches}{FindMatches}
\SetKwData{root}{root}
\SetKwData{head}{head}
\SetKwData{pattern}{pattern}
\SetKw{in}{in}


\Fn{\MatchPattern(\root, \head, \pattern)}
{

	\ForEach{node \in \root.descendant\_or\_self}{
		\If{node satisfies head constraints}
		{
			start\_nodes $\leftarrow$ node.no\_preceding

			assignment $\leftarrow$ empty list of length(pattern)

			matches $\leftarrow$ \FindMatches(start\_nodes, \pattern, node, assignment, index=0)	

			return matches
		}
	}

}
\end{algorithm}


\begin{algorithm}
\SetAlgoLined
\SetKwProg{Fn}{Function}{:}{end}
\SetKwFunction{MatchPattern}{MatchPattern}
\SetKwFunction{FindMatches}{FindMatches}
\SetKwData{root}{root}
\SetKwData{head}{head}
\SetKwData{pattern}{pattern}
\SetKw{in}{in}
\Fn{\FindMatches(next\_nodes, pattern, head\_node, variables, index)}
{


	\ForEach{node \in \root.descendant\_or\_self}{
		\If{node satisfies head constraints}
		{
			start\_nodes $\leftarrow$ node.no\_preceding

			assignment $\leftarrow$ empty list of length(pattern)

			matches = $\leftarrow$ \FindMatches(start\_nodes, \pattern, node, assignment)	
			
			return matches
		}
	}

}
\end{algorithm}


\IncMargin{1em}
\begin{algorithm}
\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\Input{A bitmap $Im$ of size $w\times l$}
\Output{A partition of the bitmap}
\BlankLine
\emph{special treatment of the first line}\;
\For{$i\leftarrow 2$ \KwTo $l$}{
\emph{special treatment of the first element of line $i$}\;
\For{$j\leftarrow 2$ \KwTo $w$}{\label{forins}
\Left$\leftarrow$ \FindCompress{$Im[i,j-1]$}\;
\Up$\leftarrow$ \FindCompress{$Im[i-1,]$}\;
\This$\leftarrow$ \FindCompress{$Im[i,j]$}\;
\If(\tcp*[h]{O(\Left,\This)==1}){\Left compatible with \This}{\label{lt}
\lIf{\Left $<$ \This}{\Union{\Left,\This}}
\lElse{\Union{\This,\Left}}
}
\If(\tcp*[f]{O(\Up,\This)==1}){\Up compatible with \This}{\label{ut}
\lIf{\Up $<$ \This}{\Union{\Up,\This}}
\tcp{\This is put under \Up to keep tree as flat as possible}\label{cmt}
\lElse{\Union{\This,\Up}}\tcp*[h]{\This linked to \Up}\label{lelse}
}
}
\lForEach{element $e$ of the line $i$}{\FindCompress{p}}
}
\caption{disjoint decomposition}\label{algo_disjdecomp}
\end{algorithm}\DecMargin{1em}

\subsection{Matching}

The matching works as following: 

\subsection{Graph Building}

Every constituent can be connected to one entity. If a pattern matches
on a constituent, a pattern gets assigned to that constituent.

\label{sec:algorithm}


\section{Examples}

\subsection{Step-by-Step Example}
Figure \ref{fig:step-by-step} shows another parsetree together with a set of rules. The process of pattern matching and graph building for each rule is displayed in table \ref{tab:step-by-step}.



\begin{figure}
\centering
\includegraphics[width=.6\linewidth]{step_example_parsetree}

\lstset{
	%caption=Descriptive Caption Text,
	numbers=left,
	frame=tb,
	xleftmargin=.15\textwidth, xrightmargin=.15\textwidth
} 

\begin{lstlisting}
 S  : NP VP .  : NP-VP      : S
 VP : V  NP PP : V-NP  PP-V : V
 PP : IN DT N  : DT-N  N-IN : IN 
 DT : a :: indefinite
\end{lstlisting}

\caption{Parsetree and rules for table \ref{tab:step-by-step}}
\label{fig:step-by-step}
\end{figure}

\begin{landscape}
\begin{table}
	\centering
	\begin{tabular}{|c|c|c|}
	  \hline  
		Pattern Match & Graph with Constituent Labels & Graph with Terminal Labels \\ \hline \hline	

		\begin{tabular}{c||c|c|c}
			$\mathtt{S}$ & $\mathtt{NP}$ & $\mathtt{V}$ & . \\ \hline
			\textbf{S} & \textbf{NP}\textsubscript{1} & \textbf{V} & \textbf{.} 
		\end{tabular} &
		\adjustbox{valign=c}{\includegraphics[scale=0.5]{step_example_raw_1}} &
		\adjustbox{valign=c}{\includegraphics[scale=0.4]{step_example_1}} \\ \hline

		\begin{tabular}{c||c|c|c}
			$\mathtt{VP}$ & $\mathtt{V}$ & $\mathtt{NP}$ & $\mathtt{PP}$ \\ \hline
			\textbf{VP} & \textbf{VBP} & \textbf{NP}\textsubscript{2} & \textbf{PP}
		\end{tabular} &
		\adjustbox{valign=c}{\includegraphics[scale=0.5]{step_example_raw_2}} &
		\adjustbox{valign=c}{\includegraphics[scale=0.4]{step_example_2}}\\ \hline

		\begin{tabular}{c||c|c|c}
			$\mathtt{PP}$ & $\mathtt{IN}$ & $\mathtt{DT}$ & $\mathtt{N}$  \\ \hline
			\textbf{PP} & \textbf{IN} & \textbf{DT}  & \textbf{NN} 
		\end{tabular} &
		\adjustbox{valign=c}{\includegraphics[scale=0.5]{step_example_raw_3}}&
		\adjustbox{valign=c}{\includegraphics[scale=0.4]{step_example_3}}\\ \hline

		\begin{tabular}{c||c}
			$\mathtt{DT}$ & $\mathtt{a}$ \\ \hline
			\textbf{DT} & a
		\end{tabular} &
		\adjustbox{valign=c}{\includegraphics[scale=0.5]{step_example_raw_4}}&
		\adjustbox{valign=c}{\includegraphics[scale=0.4]{step_example_4}}\\ \hline
	\end{tabular}
	\caption{Step-by-step application of the rules from figure \ref{fig:step-by-step}}
	\label{tab:step-by-step}

\end{table}
\end{landscape}


\subsection{Example: Hearst-Pattern}

The exact form of the first Hearst-Pattern in its original publication is:

\[
NP_0\ such\ as\ \{NP_1,\ NP_2\ ...\ ,(and|or)\}\ NP_n
\]

Expressed in the DSL this looks like:

\[
\mathtt{NP\ :\ NP0\ such\ as\ ((N\ ,)+\ \{and|or\})?\ N : N\text{--}NP0 : NP0}
\]

Since multiple and optional matching is not yet implemented, here is a version without these advanced features, that will match exactly three nouns after 'such as':

\[
\mathtt{NP\ :\ N0\ such\ as\ N1\ ,\ N2\ ,\ CC\ N3\ :\ N1\text{--}N0\ N2\text{--}N0\ N3\text{--}N0\ :\ N0}
\]

This rule applied to the sentence: "Snakes such as pythons, cobras, and boas are reptiles.", results in three edges: pythons $\rightarrow$ snakes, cobras $\rightarrow$ snakes, and boas $\rightarrow$ snakes.

\section{Conclusion}

\textbf{Acknowledgements.} This work was part of the \textit{Knoex} project (abbr. knowledge
extraction from text), which again was a subproject of the \textit{SOMA} study project at the University of Osnabrück. A working implementation can be downloaded from \url{http://github.com/mome/treepattern}. In the current version the postfix operator for optional and multiple matching as well as head-splitting is not implemented.

\bibliographystyle{apalike}
\bibliography{knoex.bib}

\end{document}
