	%% LyX 2.1.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english]{article}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage[]{algorithm2e}
\usepackage{newlfont}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{tgcursor}
\usepackage{glossaries}
\usepackage{rotating}

\graphicspath{ {images/} }
\lstset{basicstyle=\ttfamily}

\begin{document}

\title{A Domain Specific Language for Relation Extraction by Pattern Matching in Parse Trees}


\author{Moritz Meier}

\maketitle

\section{Introduction}

Due to the imense complexity and ambiguity of human language, Information
extraction (IE) from written natural language remains an unsolved
problem.

, which aimed to extract acestor\textbackslash{}
:\textbackslash{} pattern\textbackslash{} :\textbackslash{} predicates\textbackslash{}
:\textbackslash{} transformationsemantic relations from textual data
in order to construct an ontology. The algorithm described here, was
designed to harness the information of phrase structure (or constituent)
parse trees. The DSL (Domain-Specific Language) to define the patterns
is designed to 


\paragraph{Motivation}
Natural language can be seen as a \textit{serialization of thought}. In order to communicate, the sender encodes a part of his mental content into a one-dimensional representation and transmits it to the receiver who retranslates it into his own mental representation. Words that refere to entites are hereby set into relation to other concepts or entities, which can happen in arbitrary convoluted ways. Adjectives can add properties to entities, which are expressed by a noun. Prepositional clauses may modify a process or action denoted by a verb. Same words can have different meanings. Word endings contain infomation about tense or number.

Most of these combinations happen from a local to a global scale: Two adjacent words refere to an entity, a chunk of some other words may refer to something else, a chunking of them again may express a process or relation. Thus it comes natural to see a hierachical structure within each sentence. Constituency-based parse trees (or phrase-structure parse trees) are a natural way to assign a hieracical structure to a sentence. Despite beeing a syntactic method, constituency-based parse trees contain a lot explicite semantic information. Some constituents refer to a single entity or concept, others express relations between concepts.

Computational linguistics possesses various other methods to recognize properties of single words within a sentence, which provide information about undelying properties, entities and relations. POS-tagging finds the syntactic role of words, lemmatization removes inflection, NER-tagging assigs nouns to (semantic) categories. The aim of this paper it to develop a method to incorporate information of words or chunks to extract predicates that can be feed into a database or ontology.

 
\paragraph{Related Work}

The possibly best known example for pattern matching in words and
constituents of a sentence for relation extractions are Hearst-Patterns.
example Pattern Matching in trees is used in various different contexts.
One exmaple is the widely used XPath (XML Path Language), which is
a query language for node selection in XML documents, defined by the
W3C. Another python package \textit{ptTools }ialso defines a DNS for
pattern matching in parse trees, it is however intended to be applied
on python parse trees for code analysis and testing. In other cases
pattern matching is used to construct dependency parse trees from
phrase structure parse tress {[}citation{]}.

\begin{figure}

%%\centering{}\includegraphics[scale=0.4]{pathx_axes.gif}\caption{Subset of relationships expressable in XPath}

\end{figure}

Figure 1 visualizes the basic relationships that can be expressed
in XPath in order to construct more complex patterns. Patterns can
be matched on two axes, relative to a matching node denoted as \textit{self}.
On the vertical axis a higher level node can be mached as \textit{ancestor},
a lower as \textit{decendant}. A ancestor of first degree is a \textit{parent}
and a decendent of first degree a \textit{child}. On the horizontal
axis \textit{preceding} and \textit{following} nodes can be matched.
If a preceding or following also happens to be a sibling, it can be
matched with \textit{preceding-sibling} and \textit{following-sibling}.

\paragraph{Problem}

Pattern matching in tagged or parsed corpora is a common technique

in computational linguistics. A classical example for the extraction
of semantic relations from syntaxtic structures are Hearst-Patterns.

Consider the two-word sentence ``Lara jumps'' and its corresponding
parse tree.

A phrase structure parse tree captures the a 

In case the reader is unfamiliar with the abbreviation used for constituents, here is a list of all tags used in the Stanford Parser: \url{http://github.com/mome/treepattern/wiki/List-of-Constituent-Tags}


\section{Purpose (What does it?)}
...

\section{Language Features}
A program in the Domain-Specific Language consists of a list of rules. Each rule consists of four parts (root-pattern, pattern, relations and transformations), each separated by a collon: 

\[
\mathtt{root\text{-}pattern\ :\ pattern\ :\ relations\ :\ transformations}
\]

It can be red in the following way: First find a node that matches the root-pattern

Root-pattern and pattern are instructions to the pattern-matcher, the last two are define 
The head part defines the highest node, of a subtree in wich the pattern
can be matched. The pattern part is a list of terminals or constituents,
which implicitely defines a series of next-potential-follower relations.
The tansformation defines a function call.

The pattern part consists of a series of graph relations. The graph
relations are for once the graph relations also available in XPath
(child, parent, sibling, follower, ancestor) and for the other a series
of imidiate-follower relations, written in the Hearst-Pattern style.

The predicate part defines the semantic relations between the matched
strings. 

\paragraph{Macros}{
	Macros are syntactic sugar for matching multiple options.  The list bilow contains all macros currently in the system:

	\begin{lstlisting}
		V  = {VB, VBD, VBG, VBN, VBP, VBZ}
		N  = {NN, NNS, NNP, NNPS, PRP}
		W  = {WHADJP, WHAVP, WHNP, WHPP}
		SS = {S, SBAR, SBARQ, SINV, SQ}
		J  = {JJ, JJR, JJS}
	\end{lstlisting}

	With \lstinline{V} standing for verbs, \lstinline{N} for nouns, \lstinline{W} for questions, \lstinline{SS} for sentences and \lstinline{J} for adjectives. They can be used just as other variables. 
}

\paragraph{Property matching}
Matching of other properties than 'terminal' or 'label' is expressed in squared brackets after the variable name. Write a variable name and a value separated by an equal sign to check if a node has a property with that name and value. The expression \lstinline{N[ner=person]} matches nouns with the NER-tag 'person'. Write only the variable name to check if a node has a propertry with that name. \lstinline{J[color]} matches adjectives with the property 'color'. Multiple constraints are separeted by a comma: \lstinline{N[ner=person | gender=female]}.
The right hand side of a property constraint can also be a set values. In this case a constitiuent must have one of these properties to match. Example: \lstinline|DT[terminal={an,a}]| - matches a determiner with terminal 'a' or 'an'.

\paragraph{Multiple and Optional parsing}
Variables defined in pattern can occure multiple times to match multiple constituents. The relations defind for that variable are consequently applied to all matches. Example: The rule \lstinline{S : N V and V . : N-V : S} 
contains two time the variable \lstinline{V}. The rule applied to "Hanna walks and talks." will match 'walks' as well as 'talks' for \lstinline{V}. So the relation \lstinline{N-V} is formed two times, resulting in: (Hanna)$\rightarrow$ [walks], and (Hanna)$\rightarrow$ [talks].
Three postfix operators, inspiered by regular expressions, can be added to the end of a pattern token, to make the match optional or repetitive. Multiple nodes assigned to a variable are handled in same way as before.

\begin{tabular}{cll}
	$\mathbf{?}$ & optional & match once or do not match\\
	$+$ & mutliple & match at least once\\
	$*$ & multinal & match arbitrary times (inlcuding: do not match)
\end{tabular}

Example: \lstinline{NP : DT? J* N : J-N : N} matches a noun with or with or without a preceding determiner and arbitrary adjectives.


\paragraph{Cluster references}
If a sentence contains a dependent clause, one part of the sentence referece to another part of the sentence. For this purpose it is possible to specifiy a subgraph instead of a node as the head. If the root of a rule is equal to its transistions, the entities refering to the ancestors of a matching constituent will be put into a cluster. If another entity wants to point to the entity representing the root match, it will point to the cluster instead.


\begin{figure}
\centering
\includegraphics[width=.5\linewidth]{cluster_reference_parsetree}

\lstset{
	%caption=Descriptive Caption Text,
	numbers=left,
	frame=tb,
	xleftmargin=.15\textwidth, xrightmargin=.15\textwidth
} 

\begin{lstlisting}
SS : NP VP .? : NP-VP : SS
SS : IN SS1   :       : SS1
VP : V  SS    : V-SS  : V
\end{lstlisting}

\includegraphics[width=.7\linewidth]{cluster_reference_graph}

\caption{Cluster references Root and tail of line 1 are both SS: ... Line 2: "that" is ommited. Line 3: make an edge beteween the verb of the first part ("said") and the dependent clause "Lara smokes". }
\end{figure}



\paragraph{Head Splitting}
For some sentences it is desireable to let a node point to multiple other nodes. Consider this conjunction of two verb phrases: "Bob runs and cries."

\begin{figure}
\centering
\includegraphics[width=.5\linewidth]{headsplit_parsetree}

\lstset{
	%caption=Descriptive Caption Text, 
	frame=tb,
	xleftmargin=.2\textwidth, xrightmargin=.2\textwidth
}

\begin{lstlisting}
 SS : NP VP . : NP-VP : SS
 VP : VP1 CC VP2 :: VP1 VP2 
\end{lstlisting}

\includegraphics[width=.3\linewidth]{headsplit_graph}

\caption{Head Splitting: The rules in the middle applied to the parsetree on the top yield to the graph in the bottom.}
\end{figure}


\paragraph{Predicate Mode}
In predicate mode the relations part of a rule will define predicates instead of edges, with a slide changed of syntax. Example: 

\begin{lstlisting}
	S : NP1 is mother of NP2 : mother_of(NP1,NP2) : S
\end{lstlisting}


\section{Algorithm}

1 parse sentence
2 create property tree from parsetree
3 for each rule
	3.1 find subtrees where root node matches head constraints
	3.2 for each subtree
		3.2.1 find nodes without preceding nodes
		3.2.2 for each node match pattern

\subsection{Matching}

The matching works as following: 

\subsection{Graph Building}

Every constituent can be connected to one entity. If a pattern matches
on a constituent, a pattern gets assigned to that constituent.

\label{sec:algorithm}
\begin{algorithm}

parsetree $\leftarrow$ parse(sentence)

\ForEach{rule}{
	(head, pattern, predicates) $\leftarrow$ rule
	
	subtrees $\leftarrow$ nodes of parsetree that satisfy head-condition
	
	\ForEach{$subtree$}{
		matches $\leftarrow$ match(pattern, subtree)
		
		construct\_relations(matches, predictates)
	}

}

\end{algorithm}

\section{Step-by-Step Example}

\includegraphics[width=.6\linewidth]{step_example_parsetree}

\begin{lstlisting}
 S  : NP VP .  : NP-VP      : S
 VP : V  NP PP : V-NP  PP-V : V
 PP : IN DT N  : DT-N  N-IN : IN 
 DT : a :: indefinite
\end{lstlisting}

\begin{sidewaystable}
	\centering
	\caption{Step by step}
	\begin{tabular}{l|l|l}
		Pattern Match & Graph with Constituent labels & Graph with terminal labels \\ \hline

		Second First & \textbf{NP\textsubscript{1}} $\rightarrow$ \textbf{VP} &
		\includegraphics[width=.5\linewidth]{example_step1}\\ \hline

		& & \includegraphics[width=.5\linewidth]{example_step2}\\ \hline
		& & \includegraphics[width=.5\linewidth]{example_step3}\\ \hline
		& & \includegraphics[width=.5\linewidth]{example_step4}\\ \hline
	\end{tabular}
\end{sidewaystable}


\section{Example: Hearst-Pattern}

The exact form of the first Hearst-Pattern in its original publication is:

\[
NP_0\ such\ as\ \{NP_1,\ NP_2\ ...\ ,(and|or)\}\ NP_n
\]

Expressed in the DSL this looks like:

\[
\mathtt{NP\ :\ NP0\ such\ as\ ((N ,)+\ ,\ \{and|or\})?\ N : N\text{--}NP0 : NP0}
\]

Since multiple and optional matching is not yet implemented, here is a version without these advanced features, that will match exaclty three nouns after 'such as':

\[
\mathtt{NP\ :\ N0\ such\ as\ N1\ ,\ N2\ ,\ CC\ N3\ :\ N1\text{--}N0\ N2\text{--}N0\ N3\text{--}N0\ :\ N0}
\]

Applied to the sentence: "Snakes such as pythons, cobras, and boas are reptiles.", this rule results in the three edges: pythons $\rightarrow$ snakes, cobras $\rightarrow$ snakes, and boas $\rightarrow$ snakes.

\section{Conclusion}

\textbf{Acknowledgements.} This work was part of the \textit{Knoex} project (abbr. knowledge
extraction from text), which again was a subproject of the \textit{SOMA} study project at the University of Osnabrück. A working implementation can be downloaded from \url{http://github.com/mome/treepattern}. In the current version the postfix operator for optional and multiple matching as well as head-splitting is not implemented.

\bibliography{knoex.bib}{}
\bibliographystyle{plain}

\end{document}
